{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcb3966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch as torch\n",
    "import torch.utils.data as TData\n",
    "from torch import optim\n",
    "from torch.nn.parameter import Parameter\n",
    "from torchsummary import summary\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import math\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import t as gosset_t\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import plotly.express as px\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pytorch_model_summary import summary\n",
    "import random\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1e7530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import HeidelbergTraining.UNet.UNet_functions as unet_functions\n",
    "import HeidelbergTraining.UNet.UNet_model as unet_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2bca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 13\n",
    "img_size = (1, 512, 512)  # (channels, width, height)\n",
    "LAYER_NAMES_13 = [\n",
    "    \"ILM\", \n",
    "    \"RNFL\",\n",
    "    \"GCL\", \n",
    "    \"IPL\", \n",
    "    \"INL\", \n",
    "    \"OPL\", \n",
    "    \"ELM\", \n",
    "    \"PR1\", \n",
    "    \"PR2\", \n",
    "    \"RPE\", \n",
    "    \"Interlayer holes\", \n",
    "    \"BG top\", \n",
    "    \"BG bottom\"\n",
    "]\n",
    "LAYER_NAMES_14 = [\n",
    "    \"ILM\", \n",
    "    \"RNFL\",\n",
    "    \"GCL\", \n",
    "    \"IPL\", \n",
    "    \"INL\", \n",
    "    \"OPL\", \n",
    "    \"ELM\", \n",
    "    \"PR1\", \n",
    "    \"PR2\", \n",
    "    \"RPE\", \n",
    "    \"Collapsed Layers\",\n",
    "    \"Cycsts\",\n",
    "    \"Vitreous\", \n",
    "    \"Choroid/Sclera\"\n",
    "]\n",
    "LAYER_NAMES_15 = [\n",
    "    \"ILM\",   \n",
    "    \"RNFL\", \n",
    "    \"GCL\", \n",
    "    \"IPL\", \n",
    "    \"INL\", \n",
    "    \"OPL\", \n",
    "    \"ONL\", \n",
    "    \"ELM\", \n",
    "    \"PR1\", \n",
    "    \"PR2\", \n",
    "    \"RPE\", \n",
    "    \"BM\", \n",
    "    \"Interlayer holes\", \n",
    "    \"BG top\", \n",
    "    \"BG bottom\"\n",
    "]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class_weights_13 = Variable(torch.tensor([9, 6, 3, 3, 3, 3, 3, 3, 6, 6, 6, 1, 1]).float()).to(device)\n",
    "class_weights_15 = Variable(torch.tensor([9, 3, 3, 3, 3, 3, 3, 3, 6, 6, 6, 1, 1, 9, 9]).float()).to(device)\n",
    "total_path = \"./\"\n",
    "\n",
    "total_mean = 87.1074833179442\n",
    "total_std = 63.13706830280864\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766f1b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(\"images_input_unlabeled0000.png: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39870317",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./HeidelbergTraining/images_input_unlabeled_paths.txt\", \"r\") as unlabeled_original_locations:\n",
    "    data = unlabeled_original_locations.readlines()\n",
    "    data = [elem[32:].strip() for elem in data]\n",
    "    print(len(set(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e1bdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_list(path):\n",
    "    ret = []\n",
    "    for root,dirs,files in os.walk(path):\n",
    "        ret = sorted([path + \"/\" + f for f in files if f[-4:] == \".png\"])\n",
    "        if len(ret) > 0:\n",
    "            break\n",
    "    return ret\n",
    "\n",
    "image_input_labeled_path = os.path.join(total_path, \"HeidelbergTraining/images_input_labeled\")\n",
    "image_mask_path = os.path.join(total_path, \"HeidelbergTraining/images_masks\")\n",
    "baseline_img_path = os.path.join(total_path, \"HeidelbergTraining/images_baseline/baseline_images\")\n",
    "baseline_mask_path = os.path.join(total_path, \"HeidelbergTraining/images_baseline/baseline_masks\")\n",
    "baseline_full_img_path = os.path.join(total_path, \"HeidelbergTraining/images_baseline/baseline_full_image\")\n",
    "\n",
    "\n",
    "# go to images_input_labeled_paths.txt, images_masks_paths.txt for more info on these numbers\n",
    "# 80:10:10 split at patient level\n",
    "num_diseased = 292\n",
    "diseased_train_cutoff = 230\n",
    "normal_train_cutoff = 1381\n",
    "diseased_valid_cutoff = 262\n",
    "normal_valid_cutoff = 1521\n",
    "\n",
    "images_all_labeled = make_list(image_input_labeled_path)\n",
    "masks_all = make_list(image_mask_path)\n",
    "\n",
    "image_list_train = images_all_labeled[num_diseased:normal_train_cutoff]\n",
    "mask_list_train_13 = masks_all[num_diseased:normal_train_cutoff]\n",
    "\n",
    "dimgs = images_all_labeled[:diseased_train_cutoff]\n",
    "dmasks = masks_all[:diseased_train_cutoff]\n",
    "\n",
    "while len(image_list_train) < (2 * (normal_train_cutoff - num_diseased)):\n",
    "    image_list_train.extend(dimgs)\n",
    "    mask_list_train_13.extend(dmasks)\n",
    "\n",
    "del dimgs\n",
    "del dmasks\n",
    "\n",
    "d_image_list_cv = images_all_labeled[diseased_train_cutoff:diseased_valid_cutoff]\n",
    "d_mask_list_cv_13 = masks_all[diseased_train_cutoff:diseased_valid_cutoff]\n",
    "\n",
    "d_image_list_test = []\n",
    "d_mask_list_test_13 = []\n",
    "\n",
    "with open(\"./HeidelbergTraining/images_baseline_paths.txt\", \"r\") as baseline_info:\n",
    "    data = baseline_info.readlines()\n",
    "    d_mask_list_test_13 = [elem[elem.find(\":\")+2:].strip() for elem in data]\n",
    "    d_image_list_test = [\"./HeidelbergTraining/images_input_labeled/images_input_labeled%s.png\"%elem[elem.find(\".png\")-4:elem.find(\".png\")] for elem in d_mask_list_test_13]\n",
    "\n",
    "image_list_train = sorted(image_list_train)\n",
    "mask_list_train_13 = sorted(mask_list_train_13)\n",
    "\n",
    "d_image_list_cv = sorted(d_image_list_cv)\n",
    "d_mask_list_cv_13 = sorted(d_mask_list_cv_13)\n",
    "\n",
    "d_image_list_test = sorted(d_image_list_test)\n",
    "d_mask_list_test_13 = sorted(d_mask_list_test_13)\n",
    "\n",
    "baseline_images = make_list(baseline_img_path)\n",
    "baseline_masks = make_list(baseline_mask_path)\n",
    "baseline_full_images = make_list(baseline_full_img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a8afa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(images_all_labeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a65edb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_mask_train = set(mask_list_train_13)\n",
    "# percentages = np.full((13,), 0).astype(\"float32\")\n",
    "# for i, path in enumerate(set_mask_train):\n",
    "#     mask = np.array(Image.open(path))\n",
    "#     for label in range(13):\n",
    "#         percentages[label] += (np.sum(mask.ravel() == label) / (mask.shape[0] * mask.shape[1]))\n",
    "    \n",
    "# percentages /= len(set_mask_train)\n",
    "# # percentages = percentages\n",
    "# print(percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad0ac39",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i, (img_path, mask_path) in enumerate(zip(baseline_images, baseline_masks)):\n",
    "#     if i > 2:\n",
    "#         break\n",
    "#     fig,arr = plt.subplots(1,2,figsize=(14,10))\n",
    "#     img = np.array(Image.open(img_path).convert(\"L\"))\n",
    "#     mask = np.array(Image.open(mask_path).convert(\"L\"))\n",
    "    \n",
    "#     arr[0].imshow(img)\n",
    "#     arr[1].imshow(mask)\n",
    "#     fig.show()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf0b171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((np.max(percentages) / percentages).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2441e7f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7229b37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_mean = 0\n",
    "# total_squared_mean = 0\n",
    "\n",
    "# set_iter_train = set(image_list_train)\n",
    "\n",
    "# for i, path in enumerate(set_iter_train):\n",
    "#     img = np.array(Image.open(path)).astype(\"int32\")\n",
    "    \n",
    "    \n",
    "#     total_mean += np.mean(img.ravel())\n",
    "#     total_squared_mean += np.mean(np.square(img.ravel()))\n",
    "\n",
    "# total_squared_mean /= len(set_iter_train)\n",
    "# total_mean /= len(set_iter_train)\n",
    "\n",
    "# total_std = np.sqrt((total_squared_mean - np.square(total_mean)))\n",
    "\n",
    "# print(total_mean)\n",
    "# print(total_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b249f1c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# total_mean = 87.1074833179442\n",
    "# total_std = 63.13706830280864\n",
    "# set_iter_train = set(image_list_train)\n",
    "\n",
    "# mean_check = 0\n",
    "# squared_mean_check = 0\n",
    "\n",
    "# for i, path in enumerate(set_iter_train):\n",
    "#     img = (np.array(Image.open(path)) - total_mean) / total_std\n",
    "#     mean_check += np.mean(img.ravel())\n",
    "#     squared_mean_check += np.mean(np.square(img.ravel()))\n",
    "    \n",
    "\n",
    "# mean_check /= len(set_iter_train)\n",
    "# squared_mean_check /= len(set_iter_train)\n",
    "\n",
    "# std_check = np.sqrt(squared_mean_check - np.square(mean_check))\n",
    "# print(mean_check)\n",
    "# print(squared_mean_check)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a0e108",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"lengths:\")\n",
    "print(\"image list train:\\t %s\"%len(image_list_train))\n",
    "print(\"d image list test:\\t %s\"%len(d_image_list_test))\n",
    "print(\"d image list cv:\\t %s\"%len(d_image_list_cv))\n",
    "# print(\"unlabeled image list:\\t %s\"%len(uimage_list_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea34b85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_output(\n",
    "    eval_model, \n",
    "    name=\"best_model\",\n",
    "    image_path=None, \n",
    "    mask_path=None, \n",
    "    verbose=True,\n",
    "    sig_figs=6,\n",
    "    ignore_0=False,\n",
    "    Wnet=False,\n",
    "    prev_model=False\n",
    "):\n",
    "    count = 2\n",
    "    image = None\n",
    "    mask = None\n",
    "    output = None\n",
    "    \n",
    "    eval_model.eval()\n",
    "    \n",
    "    n_class = list(range(N_CLASSES))\n",
    "    if ignore_0:\n",
    "        n_class = n_class[:10] + n_class[11:]\n",
    "    \n",
    "    display_image = np.array(Image.open(image_path).convert(\"L\"))\n",
    "    \n",
    "    image = np.array(Image.open(image_path).convert(\"L\"))\n",
    "    total_mean = 87.1074833179442\n",
    "    total_std = 63.13706830280864\n",
    "    image = ((image) - total_mean) / total_std\n",
    "    image = image[np.newaxis, np.newaxis, :]\n",
    "    image = torch.from_numpy(image)\n",
    "    image = Variable(image.float()).to(device)\n",
    "    \n",
    "#     print(name + \"\\n---------------------\")\n",
    "#     print(image.shape)\n",
    "    \n",
    "    if Wnet:\n",
    "        output = prev_model(image)\n",
    "        output = torch.argmax(rearrange(output[0].detach(), 'c h w -> h w c'), dim=-1).cpu().numpy()\n",
    "        output = output[np.newaxis, np.newaxis, :]\n",
    "        \n",
    "        image = display_image[np.newaxis, np.newaxis, :]\n",
    "        image = np.concatenate((image, output), axis=1)\n",
    "        image = torch.from_numpy(image)\n",
    "        image = Variable(image.float()).to(device)\n",
    "        \n",
    "        output = eval_model(image)\n",
    "        \n",
    "    else:\n",
    "        output = eval_model(image)\n",
    "    \n",
    "    print(output.shape)\n",
    "    output = torch.argmax(rearrange(output[0].detach(), 'c h w -> h w c'), dim=-1).cpu().numpy()\n",
    "        \n",
    "    \n",
    "    if mask_path is not None:\n",
    "        count += 1\n",
    "        mask = np.array(Image.open(mask_path).convert(\"L\"))\n",
    "    \n",
    "    fig, arr = plt.subplots(1, count, figsize=(14, 10))\n",
    "    arr[0].imshow(display_image)\n",
    "    arr[0].set_title(\"(%s) - input image\"%name)\n",
    "    arr[1].imshow(output)\n",
    "    arr[1].set_title(\"(%s) - output image\"%name)\n",
    "    if count > 2:\n",
    "        arr[2].imshow(mask*20)\n",
    "        arr[2].set_title(\"(%s) - mask\"%name)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"image path: %s\"%image_path)\n",
    "        print(\"image shape: %s, %s\"%display_image.shape)\n",
    "        print(\"output shape: %s, %s\"%output.shape)\n",
    "        if count > 2:\n",
    "            print(\"mask shape: %s, %s\"%mask.shape)\n",
    "            iou_c, mean_c = unet_functions.get_iou(mask, output, n_classes=n_class)\n",
    "            print(\"IOU: \")\n",
    "            \n",
    "            names = LAYER_NAMES_13\n",
    "            if ignore_0:\n",
    "                names = LAYER_NAMES_13[:10]+LAYER_NAMES_13[11:]\n",
    "            \n",
    "            for i,l in enumerate(names):\n",
    "                pad = \"\\t\"\n",
    "                if len(l) < 6:\n",
    "                    pad += \"\\t\"\n",
    "                if len(l) < 12:\n",
    "                    pad += \"\\t\"\n",
    "                    \n",
    "                num = str(iou_c[i])\n",
    "                num = num[:sig_figs]\n",
    "                    \n",
    "                print(l + \": \" + pad + \"%s\"%num)\n",
    "            print(\"\\nMean IOU\")\n",
    "            m = str(mean_c)[:sig_figs]\n",
    "            print(\"%s\"%m)\n",
    "    print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7981c040",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(TData.Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        image_paths, \n",
    "        diseased_paths, \n",
    "        augs=None, \n",
    "        image_specs=None, \n",
    "        n_classes=13,\n",
    "        prev_model=None\n",
    "    ):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        \n",
    "        sample = []\n",
    "        \n",
    "        for i,d in zip(image_paths, diseased_paths):\n",
    "            sample.append((i,d))\n",
    "        \n",
    "        self.samples = sample\n",
    "        self.channels = image_specs[0]\n",
    "        self.rows = image_specs[1]\n",
    "        self.col = image_specs[2]\n",
    "        self.classes = n_classes\n",
    "        self.augments = augs\n",
    "        self.model = prev_model\n",
    "        self.total_std = 63.13706830280864  # calculated on training set\n",
    "        self.total_mean = 87.1074833179442 # calculated on training set\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.samples[index][0]).convert(\"L\")\n",
    "        mask = np.zeros((self.rows, self.col), dtype=np.float32)\n",
    "        \n",
    "        ssl = True if self.samples[index][1] is None else False\n",
    "        \n",
    "        if not ssl:\n",
    "            mask = Image.open(self.samples[index][1]).convert(\"L\")\n",
    "            \n",
    "        if self.augments is not None:\n",
    "            seed = random.random() * 100\n",
    "            random.seed(seed)\n",
    "            image = self.augments(image)\n",
    "            if not ssl:\n",
    "                random.seed(seed)\n",
    "                mask = self.augments(mask)\n",
    "        \n",
    "        image = np.array(image)\n",
    "        mean = np.mean(image)\n",
    "        std = np.std(image)\n",
    "        image = ((image - mean) / std)[np.newaxis, :]\n",
    "        \n",
    "        if self.model is not None:\n",
    "            self.model.train()\n",
    "            image2 = image[np.newaxis, :]\n",
    "            image2 = torch.from_numpy(image2)\n",
    "            image2 = Variable(image2.float()).to(device)\n",
    "            \n",
    "            image2 = self.model(image2)\n",
    "            image2 = torch.argmax(rearrange(image2[0].detach(), 'c h w -> h w c'), dim=-1).cpu().numpy()\n",
    "            image2 = image2[np.newaxis, :]\n",
    "            \n",
    "            image = np.concatenate((image, image2), axis=0)\n",
    "        \n",
    "        if not ssl:\n",
    "            mask = np.array(mask, dtype=np.float32)\n",
    "\n",
    "        return image, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145ccb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_unet_model = unet_models.unet_model(\n",
    "    32, \n",
    "    num_downs=4, \n",
    "    n_classes=13, \n",
    "    input_channels=1, \n",
    "    name=\"standard unet\",\n",
    ").to(device)\n",
    "state_dict = torch.load(\"./HeidelbergTraining/saved_model_pytorch/standard unet_iter1\")\n",
    "standard_unet_model.load_state_dict(state_dict)\n",
    "\n",
    "aug1 = transforms.RandomChoice([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Compose([\n",
    "        transforms.RandomCrop(size=(256, 256)),\n",
    "        transforms.Resize((512, 512), interpolation=Image.NEAREST),\n",
    "        transforms.RandomHorizontalFlip()\n",
    "    ]),\n",
    "    transforms.Compose([\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.CenterCrop((256, 256)),\n",
    "        transforms.Resize((512, 512), interpolation=Image.NEAREST),\n",
    "        transforms.RandomHorizontalFlip()\n",
    "    ]),\n",
    "    transforms.Compose([\n",
    "        transforms.RandomCrop((256, 256)),\n",
    "        transforms.Resize((512, 512), interpolation=Image.NEAREST),\n",
    "        transforms.RandomHorizontalFlip()\n",
    "    ])\n",
    "])\n",
    "\n",
    "iter_train_standard = TData.DataLoader(\n",
    "    CustomDataset(\n",
    "        image_list_train, \n",
    "        mask_list_train_13, \n",
    "        image_specs=img_size, \n",
    "        prev_model=None,\n",
    "        augs=None\n",
    "    )\n",
    ")\n",
    "\n",
    "iter_d_valid_standard = TData.DataLoader(\n",
    "    CustomDataset(d_image_list_cv, d_mask_list_cv_13, image_specs=img_size, prev_model=None)\n",
    ")\n",
    "\n",
    "iter_d_test_standard = TData.DataLoader(\n",
    "    CustomDataset(d_image_list_test, d_mask_list_test_13, image_specs=img_size, prev_model=None)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c344945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_unet_model = unet_models.unet_model(\n",
    "    32, \n",
    "    num_downs=4, \n",
    "    n_classes=13, \n",
    "    input_channels=2, \n",
    "    name=\"prev_net\",\n",
    ").to(device)\n",
    "\n",
    "state_dict = torch.load(\"./HeidelbergTraining/saved_model_pytorch/double unet_iter1\")\n",
    "double_unet_model.load_state_dict(state_dict)\n",
    "\n",
    "iter_train_double = TData.DataLoader(\n",
    "    CustomDataset(image_list_train, mask_list_train_13, image_specs=img_size, prev_model=standard_unet_model)\n",
    ")\n",
    "\n",
    "iter_d_valid_double = TData.DataLoader(\n",
    "    CustomDataset(d_image_list_cv, d_mask_list_cv_13, image_specs=img_size, prev_model=standard_unet_model)\n",
    ")\n",
    "\n",
    "iter_d_test_double = TData.DataLoader(\n",
    "    CustomDataset(d_image_list_test, d_mask_list_test_13, image_specs=img_size, prev_model=standard_unet_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92202179",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def add_13_label(output, image):\n",
    "#     avg_pooler = nn.AvgPool2d(4, stride=2).to(device)\n",
    "#     reduced_output = (avg_pooler(output[None, None, :, :].float()))[0][0].detach().cpu().numpy()\n",
    "#     reduced_image = (avg_pooler(image[:,0:1,:,:]))[0][0].detach().cpu().numpy()\n",
    "    \n",
    "#     threshold = np.percentile(reduced_image, 25)\n",
    "\n",
    "#     a = [reduced_image < threshold][0].astype(np.int8)\n",
    "#     b = [reduced_output == 0][0].astype(np.int8)\n",
    "#     b = ((a + b) // 2).astype(bool)\n",
    "\n",
    "#     yvals, xvals = np.where(b)\n",
    "#     for (x,y) in zip(xvals, yvals):\n",
    "#         output[y*2:y*2+5,x*2:x*2+5] = 13\n",
    "    \n",
    "#     return output\n",
    "\n",
    "# for i, img_path in enumerate(d_image_list_test):\n",
    "# #     if i > 0:\n",
    "# #         break\n",
    "#     image = np.array(Image.open(img_path))\n",
    "    \n",
    "#     mean = np.mean(image.ravel())\n",
    "#     std = np.std(image.ravel())\n",
    "    \n",
    "#     input_image_standard = torch.from_numpy(((image - mean) / std)[np.newaxis, :])[None, :, :, :]\n",
    "#     output_standard = standard_unet_model(Variable(input_image_standard).float().to(device))[0].detach().cpu().numpy()\n",
    "#     output_standard = np.argmax(output_standard.transpose(1,2,0), axis=-1).astype(\"uint8\")\n",
    "    \n",
    "#     input_image_double = torch.cat((input_image_standard.float(), torch.from_numpy(output_standard)[None, None, :, :].float()), dim=1)\n",
    "#     output_double = double_unet_model(Variable(input_image_double).to(device))[0].detach().cpu().numpy()\n",
    "#     output_double = np.argmax(output_double.transpose(1,2,0), axis=-1).astype(\"uint8\")\n",
    "    \n",
    "#     output_standard = add_13_label(torch.from_numpy(output_standard), input_image_standard).numpy()\n",
    "#     output_double = add_13_label(torch.from_numpy(output_double), input_image_double).numpy()\n",
    "    \n",
    "#     blend_alpha = 0.4\n",
    "    \n",
    "#     image = Image.fromarray(image.astype(\"uint8\"))\n",
    "#     blended_img_standard = Image.blend(Image.fromarray(output_standard * 19), image, blend_alpha)\n",
    "#     blended_img_double = Image.blend(Image.fromarray(output_double * 19), image, blend_alpha)\n",
    "    \n",
    "#     fig,arr = plt.subplots(1,5,figsize=(14,10))\n",
    "#     for a in arr:\n",
    "#         a.axes.get_xaxis().set_visible(False)\n",
    "#         a.axes.get_yaxis().set_visible(False)\n",
    "        \n",
    "#     arr[0].imshow(np.array(image))\n",
    "#     arr[1].imshow(output_standard)\n",
    "#     arr[2].imshow(np.array(blended_img_standard))\n",
    "#     arr[3].imshow(output_double)\n",
    "#     arr[4].imshow(np.array(blended_img_double))\n",
    "#     fig.show()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9e9655",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def calc_iou(image, mask, n_class=0):\n",
    "    image = image.astype(\"int32\")\n",
    "    mask = mask.astype(\"int32\")\n",
    "    actual_positives = mask == n_class\n",
    "    predicted_positives = image == n_class\n",
    "    \n",
    "    intersection = np.sum(np.logical_and(actual_positives, predicted_positives))\n",
    "    union = np.sum(np.logical_or(actual_positives, predicted_positives))\n",
    "    \n",
    "    if union == 0 and intersection == 0:\n",
    "        return 1\n",
    "\n",
    "    iou = intersection/union\n",
    "    return iou\n",
    "\n",
    "def get_iou(output, mask, n_classes=list(range(14))):\n",
    "    ious = []\n",
    "    for i in n_classes:\n",
    "        if i < 10:\n",
    "            ious.append(calc_iou(output, mask, i+1))\n",
    "        elif i == 10:\n",
    "            ious.append(calc_iou(output, mask, 0))\n",
    "        elif i == 11 and len(n_classes) == 14:\n",
    "            ious.append(calc_iou(output, mask, 13))\n",
    "        elif len(n_classes) == 14:\n",
    "            ious.append(calc_iou(output, mask, i-1))\n",
    "        else:\n",
    "            ious.append(calc_iou(output, mask, i))\n",
    "        \n",
    "    mean_iou = sum(ious) / len(n_classes)\n",
    "    \n",
    "    return ious, mean_iou\n",
    "\n",
    "def evaluate_model2(eval_model, iter_set, show=False, name=\"DL_pytorch\", ignore_0=False, n_classes=list(range(N_CLASSES))):\n",
    "#     eval_model.train(False)\n",
    "    ious = [[] for i in range(len(n_classes))]\n",
    "    means = []\n",
    "    \n",
    "#     eval_model.eval()\n",
    "    \n",
    "    for i, (image, mask) in enumerate(iter_set):\n",
    "        image,mask = Variable(image.float()).to(device), Variable(mask.long()).to(device)\n",
    "        output = eval_model(image)\n",
    "        \n",
    "        output = torch.argmax(rearrange(output[0].detach(), 'c h w -> h w c'), dim=-1)\n",
    "        \n",
    "        avg_pooler = nn.AvgPool2d(4, stride=2).to(device)\n",
    "    \n",
    "        reduced_mask = (avg_pooler(mask[None, :, :, :].float()))[0][0].detach().cpu().numpy()\n",
    "        reduced_output = (avg_pooler(output[None, None, :, :].float()))[0][0].detach().cpu().numpy()\n",
    "        reduced_image = (avg_pooler(image[:,0:1,:,:]))[0][0].detach().cpu().numpy()\n",
    "        \n",
    "        \n",
    "        output = output.cpu().numpy()\n",
    "        image = image[0][0].cpu().numpy()\n",
    "        mask = mask[0].cpu().numpy()\n",
    "\n",
    "        threshold = np.percentile(reduced_image, 25)\n",
    "\n",
    "        a = [reduced_image < threshold][0].astype(np.int8)\n",
    "        b = [reduced_output == 0][0].astype(np.int8)\n",
    "        b = ((a + b) // 2).astype(bool)\n",
    "\n",
    "        a = [reduced_image < threshold][0].astype(np.int8)\n",
    "        c = [reduced_mask == 0][0].astype(np.int8)\n",
    "        c = ((a + c) // 2).astype(bool)\n",
    "        \n",
    "        yvals, xvals = np.where(c)\n",
    "        for (x,y) in zip(xvals, yvals):\n",
    "            mask[y*2:y*2+5,x*2:x*2+5] = 13\n",
    "\n",
    "        yvals, xvals = np.where(b)\n",
    "        for (x,y) in zip(xvals, yvals):\n",
    "            output[y*2:y*2+5,x*2:x*2+5] = 13\n",
    "        \n",
    "        if show:\n",
    "            fig, arr = plt.subplots(1, 3, figsize=(14,10))\n",
    "            arr[0].imshow(mask)\n",
    "            arr[0].set_title(\"gt %s\"%i)\n",
    "            arr[1].imshow(output)\n",
    "            arr[1].set_title(\"prediction %s\"%i)\n",
    "            arr[2].imshow(image)\n",
    "            arr[2].set_title(\"input %s\"%i)\n",
    "            fig.show()\n",
    "            plt.show()\n",
    "        \n",
    "        iou_c, mean_c = get_iou(mask, output, n_classes=range(14))\n",
    "        \n",
    "        means.append(mean_c)\n",
    "        for j in range(len(ious)):\n",
    "            if j >= len(iou_c):\n",
    "                ious[j].append(0)\n",
    "            else:\n",
    "                ious[j].append(iou_c[j])\n",
    "                \n",
    "    means = sum(means)/len(means)\n",
    "    iou_data = []\n",
    "    for layer_name,layer in enumerate(ious):\n",
    "        iou_data.extend([(name, layer_name, layer_i) for layer_i in layer])\n",
    "        \n",
    "    iou_data = pd.DataFrame(iou_data, columns=[\"Class\", \"layer\", \"IOU\"])\n",
    "    \n",
    "    return iou_data,means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6332155e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline_ious(baseline_img_path_list, baseline_mask_path_list):\n",
    "    ious = [[] for i in range(14)]\n",
    "    means = []\n",
    "    \n",
    "    for i, (img_path, mask_path) in enumerate(zip(baseline_img_path_list, baseline_mask_path_list)):\n",
    "        baseline_img = np.array(Image.open(img_path).convert(\"L\"))\n",
    "        baseline_mask = np.array(Image.open(mask_path).convert(\"L\"))\n",
    "        \n",
    "        iou_c, mean_c = get_iou(baseline_mask, baseline_img, n_classes=range(14))\n",
    "        means.append(mean_c)\n",
    "        for j in range(len(ious)):\n",
    "            if j == 10 or j == 11:\n",
    "                continue\n",
    "            ious[j].append(iou_c[j])\n",
    "#             if j >= len(iou_c):\n",
    "#                 ious[j].append(0)\n",
    "#             else:\n",
    "#                 ious[j].append(iou_c[j])\n",
    "        ious[10].append(0)\n",
    "        ious[11].append(0)\n",
    "            \n",
    "    means = sum(means)/len(means)\n",
    "    \n",
    "    iou_data = []\n",
    "    name = \"Heidelberg Auto\"\n",
    "    for layer_name,layer in enumerate(ious):\n",
    "        iou_data.extend([(name, layer_name, layer_i) for layer_i in layer])\n",
    "        \n",
    "    iou_data = pd.DataFrame(iou_data, columns=[\"Class\", \"layer\", \"IOU\"])\n",
    "    \n",
    "    return iou_data,means\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61476ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_name = \"Semi-Supervised\"\n",
    "standard_name = \"Standard UNet\"\n",
    "double_name = \"Double UNet\"\n",
    "baseline_name = \"Heidelberg Auto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172d6f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_baseline, mean_baseline = get_baseline_ious(baseline_images, baseline_masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75ecea5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "standard_unet_model = standard_unet_model.train()\n",
    "iou_standard, mean_standard = evaluate_model2(standard_unet_model, iter_d_test_standard, name=standard_name, show=False, n_classes=list(range(14)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ab331",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "double_unet_model.train()\n",
    "iou_double, mean_double = evaluate_model2(double_unet_model, iter_d_test_double, name=double_name, show=False, n_classes=list(range(14)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5ca0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_cps = pd.read_csv(\"./HeidelbergTraining/CPS_data.csv\")\n",
    "mean_cps = np.mean(iou_cps[\"IOU\"])\n",
    "iou_cps[\"Class\"] = dl_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b5844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = iou_cps.append(iou_standard.append(iou_double.append(iou_baseline)))\n",
    "\n",
    "# ious = iou_standard.append(iou_double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebd65d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb4c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dict(iou):\n",
    "    fig = px.box(iou, x=\"layer\", y=\"IOU\", color=\"Class\")\n",
    "    fig.update_layout(\n",
    "        xaxis = dict(\n",
    "            tickmode = 'array',\n",
    "            tickvals = list(range(14)),\n",
    "            ticktext = LAYER_NAMES_14\n",
    "        ),\n",
    "        boxgap=.7,\n",
    "    #         title=\"IOUs of different model architectures on the diseased test set by layer\",\n",
    "        title=\"IOU comparison of different models on the diseased test set\",\n",
    "        legend=dict(\n",
    "            y=-0.35,\n",
    "            x=0.01\n",
    "        ),\n",
    "        height=650\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "plot_dict(ious)\n",
    "print(\"Standard mean IOU:\\t\\t %10f\"%mean_standard)\n",
    "print(\"Double mean IOU:\\t\\t %10f\"%mean_double)\n",
    "print(\"Heidelberg Auto mean IOU:\\t %10f\"%mean_baseline)\n",
    "print(\"CPS mean IOU:\\t\\t\\t %10f\"%mean_cps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c526fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ious = []\n",
    "order = [dl_name, standard_name, double_name, baseline_name]\n",
    "for layer in np.unique(ious[\"layer\"]):\n",
    "    layer_ious = ious[ious[\"layer\"] == layer]\n",
    "    \n",
    "    l_iou = [LAYER_NAMES_14[layer]]\n",
    "    for method in order:\n",
    "        l_iou.append(np.mean(layer_ious[layer_ious[\"Class\"] == method][\"IOU\"]))\n",
    "    \n",
    "    mean_ious.append(tuple(l_iou))\n",
    "mean_ious = pd.DataFrame(mean_ious, columns=([\"layer\"] + order))\n",
    "# print(mean_ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487d41f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ious.to_csv(\"./HeidelbergTraining/IOU_tables.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865927a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = ious\n",
    "df3_ious = np.array(df3[\"IOU\"])\n",
    "df3_dice = (2 * df3_ious) / (1 + df3_ious)\n",
    "df3 = df3.replace(to_replace=df3_ious, value=df3_dice)\n",
    "df3 = df3.rename(columns={\"IOU\":\"Dice\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae862d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(df3, x=\"layer\", y=\"Dice\", color=\"Class\")\n",
    "fig.update_layout(\n",
    "    xaxis = dict(\n",
    "        tickmode = 'array',\n",
    "        tickvals = list(range(14)),\n",
    "        ticktext = LAYER_NAMES_14\n",
    "    ),\n",
    "    boxgap=.7,\n",
    "#         title=\"IOUs of different model architectures on the diseased test set by layer\",\n",
    "    title=\"Dice comparison of different models on the diseased test set\",\n",
    "    legend=dict(\n",
    "        y=-0.35,\n",
    "        x=0.01\n",
    "    ),\n",
    "    height=650\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b082f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dices = []\n",
    "order = [dl_name, standard_name, double_name, baseline_name]\n",
    "for layer in np.unique(df3[\"layer\"]).astype(\"uint8\"):\n",
    "    layer_dices = df3[df3[\"layer\"] == layer]\n",
    "    \n",
    "    l_dice = [LAYER_NAMES_14[layer]]\n",
    "    for method in order:\n",
    "        l_dice.append(np.mean(layer_dices[layer_dices[\"Class\"] == method][\"Dice\"]))\n",
    "    \n",
    "    mean_dices.append(tuple(l_dice))\n",
    "mean_dices = pd.DataFrame(mean_dices, columns=([\"layer\"] + order))\n",
    "# print(mean_dices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8c86a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dices.to_csv(\"./HeidelbergTraining/Dice_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c06ee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_iou_list(iou_df, layer=0):\n",
    "    rows = iou_df[iou_df[\"layer\"] == layer]\n",
    "    return np.array(rows[\"IOU\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a27d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval(iou_list, alpha=0.05):\n",
    "    num = len(iou_list)\n",
    "    sd = np.std(iou_list)\n",
    "    mean = np.mean(iou_list)\n",
    "    qtiles = np.array([-1, 1]) * gosset_t.ppf(q=[1 - alpha / 2], df = num-1)\n",
    "    return ((qtiles * sd) / math.sqrt(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ffaba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bootstrap(bootstrap_data, num_indices=100):\n",
    "    bootstrap_data.sort()\n",
    "    x_start = int(bootstrap_data[0] * 100) - 1\n",
    "    x_end = int(bootstrap_data[-1] * 100) + 1\n",
    "\n",
    "    step = (x_end - x_start) / num_indices\n",
    "    x = np.arange(x_start, x_end+1, step) / 100\n",
    "\n",
    "    step = x[1] - x[0]\n",
    "    y = []\n",
    "    for i in range(len(x)):\n",
    "        y.append(np.sum(np.logical_and(bootstrap_data > x[i] - step / 2, bootstrap_data < x[i] + step / 2)))\n",
    "    y = np.array(y) / len(bootstrap_data)\n",
    "\n",
    "    mean = np.sum(np.multiply(x,y))\n",
    "    std = math.sqrt(np.sum(np.multiply(np.square(x), y)) - (mean * mean))\n",
    "    \n",
    "    plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bootstrap(data_list, num_reps=10000, verbose=False):\n",
    "    bootstrap_distribution = []\n",
    "    mean = []\n",
    "    std = []\n",
    "    bootstrap_distribution = []\n",
    "    \n",
    "    bootstrap_distribution.append(np.mean(data_list))\n",
    "    \n",
    "    for j in range(num_reps):\n",
    "        sample_distro = []\n",
    "        for k in range(len(data_list)):\n",
    "            sample_distro.append(data_list[random.randint(0, len(data_list) - 1)])\n",
    "        bootstrap_distribution.append(np.mean(sample_distro))\n",
    "        \n",
    "    if verbose:\n",
    "        plot_bootstrap(bootstrap_distribution, num_indices=100)\n",
    "    \n",
    "    return bootstrap_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae964514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dice_list(iou_df, layer=0):\n",
    "    iou_list = df_to_iou_list(iou_df, layer=layer)\n",
    "    return np.divide((iou_list * 2), (iou_list + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238a62a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "order = [dl_name, standard_name, double_name, baseline_name]\n",
    "\n",
    "for method in order:\n",
    "    iou_method = ious[ious[\"Class\"] == method]\n",
    "    iou_method_list = np.array(iou_method[\"IOU\"])\n",
    "    distro = calc_bootstrap(iou_method_list)\n",
    "    print(1.96*np.std(distro))\n",
    "    print(method)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0de2a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = [dl_name, standard_name, double_name, baseline_name]\n",
    "\n",
    "for method in order:\n",
    "    dice_method = df3[df3[\"Class\"] == method]\n",
    "    dice_method_list = np.array(dice_method[\"Dice\"])\n",
    "    dice_method_list = np.divide((dice_method_list * 2), (dice_method_list + 1))\n",
    "    distro = calc_bootstrap(iou_method_list)\n",
    "    print(1.96*np.std(distro))\n",
    "    print(method)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c976ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = [dl_name, standard_name, double_name, baseline_name]\n",
    "\n",
    "confidence_intervals = []\n",
    "for i in range(14):\n",
    "    c_i = []\n",
    "    for method in order:\n",
    "        iou_method = ious[ious[\"Class\"] == method]\n",
    "        iou_method_list = df_to_iou_list(iou_method, layer=i)\n",
    "        distro = calc_bootstrap(iou_method_list)\n",
    "        c_i.append(1.96*np.std(distro))\n",
    "    \n",
    "    confidence_intervals.append(tuple(c_i))\n",
    "\n",
    "confidence_intervals = pd.DataFrame(confidence_intervals, columns=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ec7838",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "order = [dl_name, standard_name, double_name, baseline_name]\n",
    "\n",
    "confidence_intervals_dice = []\n",
    "for i in range(14):\n",
    "    print(i)\n",
    "    c_i = []\n",
    "    for method in order:\n",
    "        dice_method = df3[df3[\"Class\"] == method]\n",
    "        dice_method_list = np.array(dice_method[dice_method[\"layer\"] == i][\"Dice\"])\n",
    "        distro = calc_bootstrap(dice_method_list)\n",
    "        c_i.append(1.96*np.std(distro))\n",
    "    \n",
    "    confidence_intervals_dice.append(tuple(c_i))\n",
    "\n",
    "confidence_intervals_dice = pd.DataFrame(confidence_intervals_dice, columns=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea351c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = [dl_name, standard_name, double_name, baseline_name]\n",
    "\n",
    "confidence_intervals_dice2 = []\n",
    "for i in range(14):\n",
    "    print(i)\n",
    "    c_i = []\n",
    "    for method in order:\n",
    "        dice_method = ious[ious[\"Class\"] == method]\n",
    "        dice_method_list = df_to_dice_list(dice_method, layer=i)\n",
    "        distro = calc_bootstrap(dice_method_list)\n",
    "        c_i.append(1.96*np.std(distro))\n",
    "    \n",
    "    confidence_intervals_dice2.append(tuple(c_i))\n",
    "\n",
    "confidence_intervals_dice2 = pd.DataFrame(confidence_intervals_dice2, columns=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcd2def",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in order:\n",
    "    print(method)\n",
    "    for elem in np.array(confidence_intervals_dice[method]):\n",
    "        print(elem)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a031e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
