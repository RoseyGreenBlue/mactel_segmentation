{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "520b0fca",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0744a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# import torch as torch\n",
    "# import torch.utils.data as TData\n",
    "# from torch import optim\n",
    "# from torch.nn.parameter import Parameter\n",
    "# from torchsummary import summary\n",
    "# from torch.autograd import Variable\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.vq import vq, kmeans, whiten\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b3e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch-model-summary    0.1.2       \n",
    "# torch                    0.4.1       \n",
    "# torchfile                0.1.0       \n",
    "# torchsummary             1.5.1       \n",
    "# torchtext                0.2.1       \n",
    "# torchvision              0.2.0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd53cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import HeidelbergTraining.UNet.UNet_functions as unet_functions\n",
    "import HeidelbergTraining.UNet.UNet_model as unet_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef606f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_path = \"./\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36861a82",
   "metadata": {},
   "source": [
    "# loading labeled input images and matching them with their labeled segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7bff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_path = os.path.join(total_path, \"data/NORMAL EYES_segmented_FIN\")\n",
    "diseased_path = os.path.join(total_path, \"data/Segmentations diseased eyes - MacTel/MacTel eyes, no segmentation\")\n",
    "print(os.path.isdir(normal_path))\n",
    "print(os.path.isdir(diseased_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2decc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dirs = []\n",
    "for dirpath, dirs, files in os.walk(normal_path):\n",
    "    if len(dirs) > 0:\n",
    "        all_dirs.extend(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc835f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for i, (dirpath, dirs, files) in enumerate(os.walk(normal_path)):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    filenames = [os.path.join(normal_path, all_dirs[i - 1], f) for f in files if f.endswith(\".png\")]\n",
    "    all_files.extend(filenames)\n",
    "\n",
    "for i, (dirpath, dirs, files) in enumerate(os.walk(diseased_path)):\n",
    "    filenames = [os.path.join(diseased_path, f) for f in files if f.endswith(\".png\")]\n",
    "    all_files.extend(filenames)\n",
    "\n",
    "all_image_files = [file for file in all_files if (\"NHORC\" in file or \"MacTel eyes, no segmentation\" in file)] \n",
    "for f in all_image_files:\n",
    "    if not os.path.isfile(f):\n",
    "        print(\"bruh\")\n",
    "    \n",
    "all_image_files = list(set(all_image_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5ed0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_image_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec03f066",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_path = os.path.join(total_path, \"data/NORMAL EYES_segmented_FIN\")\n",
    "diseased_path = os.path.join(total_path, \"data/Segmentations diseased eyes - MacTel/MacTel eyes, segmentations indicating interruptions of  layers\")\n",
    "print(os.path.isdir(normal_path))\n",
    "print(os.path.isdir(diseased_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afda1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dirs = []\n",
    "for dirpath, dirs, files in os.walk(normal_path):\n",
    "    if len(dirs) > 0:\n",
    "        all_dirs.extend(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e845e7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for i, (dirpath, dirs, files) in enumerate(os.walk(normal_path)):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    filenames = [os.path.join(normal_path, all_dirs[i - 1], f) for f in files if f.endswith(\".png\")]\n",
    "    all_files.extend(filenames)\n",
    "\n",
    "for i, (dirpath, dirs, files) in enumerate(os.walk(diseased_path)):\n",
    "    filenames = [os.path.join(diseased_path, f) for f in files if f.endswith(\".png\")]\n",
    "    all_files.extend(filenames)\n",
    "\n",
    "    \n",
    "all_mask_files = [file for file in all_files if (\"NHORC\" not in file and \"MacTel eyes, no segmentation\" not in file)]\n",
    "\n",
    "for f in all_mask_files:\n",
    "    if not os.path.isfile(f):\n",
    "        print(\"bruh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c06abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_mask_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7543420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numbers(file_path):\n",
    "    name = file_path[file_path.find(\"NHORC\") + 5:-4] if (\"NHORC\" in file_path) else file_path[file_path.find(\"NHOR\") + 4:-4]\n",
    "    words = name.split()\n",
    "    new_words = []\n",
    "    for w in words:\n",
    "        new_words.extend(w.split(\",\"))\n",
    "\n",
    "    words = []\n",
    "    for w in new_words:\n",
    "        words.extend(w.split(\"_\"))\n",
    "        \n",
    "    new_words = words\n",
    "    words = []\n",
    "    \n",
    "    for w in new_words:\n",
    "        words.extend(w.split(\".\"))\n",
    "\n",
    "    numbers = []\n",
    "    for f in words:\n",
    "        if \"-\" in f and f[0].isdigit():\n",
    "            numbers.append(f)\n",
    "            continue\n",
    "        if f.isdigit():\n",
    "            numbers.append(f)\n",
    "    \n",
    "    return numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b50925e",
   "metadata": {},
   "source": [
    "# match gt file paths to image file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d8a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_list = []\n",
    "mask_path_list = []\n",
    "\n",
    "i = 0\n",
    "count = 0\n",
    "\n",
    "all_mask_files_names = [f[f.find(\"NHOR\"):] for f in all_mask_files]\n",
    "\n",
    "for file in sorted(all_image_files):\n",
    "#     if i > 0:\n",
    "# #         print(file)\n",
    "#         break\n",
    "        \n",
    "    which_eye = \"OD\" if \"OD\" in file else \"OS\" if \"OS\" in file else \"\"\n",
    "    \n",
    "    numbers = get_numbers(file)\n",
    "        \n",
    "#     print(numbers)\n",
    "#     print(which_eye)\n",
    "    \n",
    "    match = [i for i in range(len(all_mask_files_names)) if numbers[0] in all_mask_files_names[i] and numbers[1] in all_mask_files_names[i] and which_eye in all_mask_files_names[i]]\n",
    "    if len(match) > 1:\n",
    "        actual_match = [i for i in match if \"NHORC\" not in all_mask_files_names[i] and numbers[1] in all_mask_files_names[i][all_mask_files_names[i].find(numbers[0])+len(numbers[0]):]]\n",
    "#         print(file)\n",
    "#         print(numbers)\n",
    "#         print()\n",
    "#         print()\n",
    "        if len(actual_match) > 0:\n",
    "            mask_path_list.append(\"%s%s\"%(count, all_mask_files[actual_match[0]]))\n",
    "            image_path_list.append(\"%s%s\"%(count, file))\n",
    "            count += 1\n",
    "        \n",
    "        continue\n",
    "\n",
    "    if len(match) == 1:\n",
    "        actual_match = [i for i in match if \"NHORC\" not in all_mask_files_names[i]]\n",
    "        \n",
    "        if len(actual_match) > 0:\n",
    "            mask_path_list.append(\"%s%s\"%(count, all_mask_files[actual_match[0]]))\n",
    "            image_path_list.append(\"%s%s\"%(count, file))\n",
    "            count += 1\n",
    "#     print(match)\n",
    "    \n",
    "    i += 1\n",
    "print(count)\n",
    "image_path_list = sorted(image_path_list)\n",
    "mask_path_list = sorted(mask_path_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427fe151",
   "metadata": {},
   "source": [
    "# helper functions for extracting crops from OCTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268a7d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_black_white(img):\n",
    "    sums = np.sum(img, axis=0)\n",
    "    \n",
    "    sums = [f / 1000 for f in sums]\n",
    "    diffs = [sums[i] - sums[i-1] for i in range(1,len(sums))]\n",
    "    min_diffs = min(diffs)\n",
    "    max_diffs = max(diffs)\n",
    "    \n",
    "    x_crop_start = [i for i in range(len(diffs)) if diffs[i] == min_diffs][0]\n",
    "    x_crop_end = [i for i in range(len(diffs)) if diffs[i] == max_diffs][0]\n",
    "    \n",
    "    return img[50:-100, x_crop_start:x_crop_end], x_crop_start, x_crop_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d26f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_to_img(img_gt, img_to_match, pixel_move=10):\n",
    "    sums1 = np.sum(img_gt, axis=1) / 10000\n",
    "    sums2 = np.sum(img_to_match, axis=1) / 10000\n",
    "    \n",
    "    pixel_move = 10\n",
    "    min_diff = np.sum(np.absolute(sums1 - sums2))\n",
    "    \n",
    "    moving_img = img_to_match\n",
    "    \n",
    "    total_pixel_move = 0\n",
    "    num_iters = img_gt.shape[0] // pixel_move\n",
    "    if num_iters * pixel_move < img_gt.shape[0]:\n",
    "        num_iters += 1\n",
    "    \n",
    "    for i in range(num_iters + pixel_move):\n",
    "        sums2 = np.concatenate((sums2[pixel_move:], sums2[:pixel_move]), axis=0)\n",
    "        curr_diff = np.sum(np.absolute(sums1 - sums2))\n",
    "        \n",
    "        if curr_diff < min_diff:\n",
    "            min_diff = curr_diff\n",
    "            img_to_match = moving_img\n",
    "            total_pixel_move = (i+1) * pixel_move\n",
    "    \n",
    "    return total_pixel_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf75f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentile(img, percentile):\n",
    "    img = np.sort(img.ravel())\n",
    "    index = (np.shape(img.ravel())[0] - 1) * percentile / 100\n",
    "    return img[int(index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41def2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_cropped(img, threshold=80):\n",
    "    y_sums = np.array(np.sum(img, axis=1)) / 1000\n",
    "    yaverage = int(np.mean(np.where(y_sums > np.percentile(y_sums, threshold))[0]))\n",
    "    \n",
    "    x_slice = img[yaverage, :]\n",
    "    xaverage = int(np.mean(np.where(x_slice > np.percentile(x_slice, threshold))[0]))\n",
    "    \n",
    "    pad = 256\n",
    "    \n",
    "    ystart = yaverage - pad if yaverage - pad >= 0 else 0\n",
    "    xstart = xaverage - pad if xaverage - pad >= 0 else 0\n",
    "    \n",
    "    yend = yaverage + pad if yaverage + pad < img.shape[0] else img.shape[0]\n",
    "    xend = xaverage + pad if xaverage + pad < img.shape[1] else img.shape[1]\n",
    "    \n",
    "    min_length = xend - xstart if (xend - xstart) < (yend - ystart) else yend - ystart\n",
    "    xaverage = xstart + (xend - xstart) // 2\n",
    "    yaverage = ystart + (yend - ystart) // 2\n",
    "\n",
    "        \n",
    "    if min_length < 128:\n",
    "        return None, -1, -1\n",
    "        \n",
    "    elif min_length < 256:\n",
    "        min_length = 128\n",
    "    \n",
    "    elif min_length < 512:\n",
    "        min_length = 256\n",
    "    \n",
    "    else:\n",
    "        min_length = 512\n",
    "        \n",
    "    ystart = yaverage - min_length // 2\n",
    "    yend = yaverage + min_length // 2\n",
    "    \n",
    "    xstart = xaverage - min_length // 2\n",
    "    xend = xaverage + min_length // 2\n",
    "    \n",
    "    return img[ystart:ystart + min_length, xstart:xstart + min_length], xstart, ystart\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33ba700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_channels_to_front(img, num_channels):\n",
    "    new_img = img[:,:,0][np.newaxis, :, :]\n",
    "    for i in range(1,num_channels):\n",
    "        new_img = np.concatenate((new_img, img[:,:,i][np.newaxis, :, :]), axis=0)\n",
    "    \n",
    "    return np.array(new_img)\n",
    "\n",
    "def move_channels_to_back(img, num_channels):\n",
    "    new_img = img[0,:,:][:, :, np.newaxis]\n",
    "    for i in range(1, num_channels):\n",
    "        new_img = np.concatenate((new_img, img[i, :, :][:, :, np.newaxis]), axis=-1)\n",
    "    \n",
    "    return np.array(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85548e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_to_512(img):\n",
    "    if img.shape[0] == 512:\n",
    "        return img\n",
    "    resize_scalar = 512 //img.shape[0]\n",
    "    ret_img = None\n",
    "    num_channels = 3\n",
    "    \n",
    "    if len(img.shape) == 2:\n",
    "        img = img[:, :, np.newaxis]\n",
    "        num_channels = 1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        img_tensor = torch.from_numpy(move_channels_to_front(img, img.shape[-1]))[None, :, :, :].to(torch.float32).to(device)\n",
    "\n",
    "        up_conv_weight = torch.ones((resize_scalar,resize_scalar))[None,None,:].to(torch.float32).to(device)\n",
    "        if num_channels == 3:\n",
    "            up_conv_weight = nn.Parameter(torch.cat((up_conv_weight,up_conv_weight,up_conv_weight), dim=0))\n",
    "\n",
    "        ret_img = F.conv_transpose2d(img_tensor, up_conv_weight, stride=(resize_scalar, resize_scalar), groups=num_channels)\n",
    "        ret_img = move_channels_to_back(ret_img[0], ret_img.shape[1]).astype(\"uint8\")\n",
    "    \n",
    "    if num_channels == 3:\n",
    "        return ret_img\n",
    "    \n",
    "    return ret_img[:, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e70c78",
   "metadata": {},
   "source": [
    "# recording unique colors and their label in color_dict_new.json and color_dict_new_diseased.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80abf850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def put_in_new_data_dictionary(color_images):\n",
    "    labeled_colors = {}\n",
    "    \n",
    "    for i, img in enumerate(color_images):\n",
    "        print(\".\", end=\"\")\n",
    "        unrolled = np.stack((img[:, :, 0].ravel(), img[:, :, 1].ravel(), img[:, :, 2].ravel()), axis=1)\n",
    "        index_gray = np.logical_and(np.logical_and(unrolled[:, 0] == unrolled[:, 1], unrolled[:, 1] == unrolled[:, 2]), unrolled[:, 0] == unrolled[:, 2])\n",
    "        unrolled[index_gray] = (0,0,0)\n",
    "        unrolled = np.reshape(np.sum(unrolled, axis=-1), (img.shape[0], img.shape[1]))\n",
    "\n",
    "        labeled_lines = np.full(unrolled.shape, 0)\n",
    "\n",
    "        x_slices = [unrolled[:, i] for i in range(img.shape[1])]\n",
    "        complete_xs = []\n",
    "\n",
    "        for i in range(len(x_slices)):\n",
    "            count_up = [index for index in range(len(x_slices[i]) - 1) if (x_slices[i][index] == 0 and x_slices[i][index + 1] != 0) or (x_slices[i][index] != 0 and x_slices[i][index + 1] == 0)]\n",
    "            if len(count_up) == 22:\n",
    "                for j in range(0, len(count_up), 2):\n",
    "                    ystart = count_up[j] + 1\n",
    "                    yend = count_up[j+1] + 1\n",
    "                    valid_colors = img[ystart:yend, i]\n",
    "                    valid_colors = [\"%s\"%((pt[0] << 16) | (pt[1] << 8) | pt[2]) for pt in valid_colors]\n",
    "                    corr_labels = [(j // 2 + 1)] * len(valid_colors)\n",
    "\n",
    "                    for key, value in zip(valid_colors, corr_labels):\n",
    "                        labeled_colors[key] = value\n",
    "\n",
    "    print(\"\\nnew length of dictionary: %5d\"%len(labeled_colors))\n",
    "    \n",
    "    with open('color_dict_new.json', 'w') as save_file:\n",
    "        save_file.write(json.dumps(labeled_colors))\n",
    "\n",
    "# print(len(color_images))\n",
    "# put_in_new_data_dictionary(color_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3f8550",
   "metadata": {},
   "source": [
    "# process labeled segmentations and turn them into ground truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a4cf21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def label_lines(color_images):\n",
    "\n",
    "    color_images_labeled = []\n",
    "    \n",
    "    with open('color_dict_new.json', 'r') as save_file:\n",
    "        cDict = json.load(save_file)\n",
    "        print(len(cDict))\n",
    "        for i, img in enumerate(color_images):\n",
    "            print(\".\", end=\"\")\n",
    "            unrolled = np.stack((img[:, :, 0].ravel(), img[:, :, 1].ravel(), img[:, :, 2].ravel()), axis=1).astype(\"int32\")\n",
    "            index_gray = np.logical_and(np.logical_and(unrolled[:, 0] == unrolled[:, 1], unrolled[:, 1] == unrolled[:, 2]), unrolled[:, 0] == unrolled[:, 2])\n",
    "            index_color = np.logical_not(index_gray)\n",
    "            unrolled[index_gray] = (0,0,0)\n",
    "            # encoding color tuple to integer using bitwise operators\n",
    "            # (255, 170, 35) -> (255 << 16) | (170 << 8) | (35 << 0)\n",
    "            unrolled = np.bitwise_or(np.bitwise_or(np.left_shift(unrolled[:, 0], 16), np.left_shift(unrolled[:, 1], 8)), unrolled[:, 2]) \n",
    "\n",
    "            labeled_lines = np.full(unrolled.shape, 0)\n",
    "            keys = cDict.keys()\n",
    "\n",
    "            labeled_lines[index_color] = [cDict[\"%s\"%pt] if \"%s\"%pt in cDict.keys() else 0 for pt in unrolled[index_color]]\n",
    "\n",
    "            labeled_lines = np.reshape(labeled_lines, (img.shape[0], img.shape[1]))\n",
    "            color_images_labeled.append(labeled_lines)\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    return color_images_labeled\n",
    "#         fig, arr = plt.subplots(1,1,figsize=(14,10))\n",
    "#         arr.imshow(labeled_lines)\n",
    "#         fig.show()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a14b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_col_distinct_bool_array(raveled_transposed_boolean_arr, original_img_shape):\n",
    "    pts = np.array(np.where(raveled_transposed_boolean_arr)[0])\n",
    "    col = pts // original_img_shape[1]\n",
    "    row = pts % original_img_shape[1]\n",
    "    \n",
    "    num_distinct = [0] * (img.shape[1]+1)\n",
    "    prev = 0\n",
    "    for elem in col:\n",
    "        prev += 1\n",
    "        num_distinct[elem+1] = prev\n",
    "    \n",
    "    return row, col, num_distinct\n",
    "\n",
    "def get_index(raveled_transposed_img, label, original_img_shape):\n",
    "    return row_col_distinct_bool_array(raveled_transposed_img == label, original_img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51b13d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill(img, baseline=False):\n",
    "    \n",
    "    raveled_transposed_img = img.T.ravel()\n",
    "    \n",
    "    if (baseline):\n",
    "        \n",
    "        row_end, col_end, num_distinct_end = row_col_distinct_bool_array(raveled_transposed_img != 0, img.shape)\n",
    "        \n",
    "        for col in range(img.shape[1]):\n",
    "            prev_color = 1\n",
    "            start = False\n",
    "            color_end = row_end[num_distinct_end[col+1] - 1]\n",
    "            for row in range(color_end):\n",
    "                if img[row, col] == 0:\n",
    "                    if start:\n",
    "                        img[row, col] = prev_color\n",
    "                else:\n",
    "                    if img[row, col] > prev_color:\n",
    "                        prev_color = img[row, col]\n",
    "                    \n",
    "                    if not start:\n",
    "                        prev_color = img[row, col]\n",
    "                    \n",
    "                    start = True\n",
    "            \n",
    "            img[color_end:, col] = 12\n",
    "    else:\n",
    "        for label in range(1,11):\n",
    "            row, col, num_distinct = get_index(raveled_transposed_img, label, (512,512))\n",
    "            row_next, col_next, num_distinct_next = get_index(raveled_transposed_img, label+1, (512,512))\n",
    "\n",
    "            for i in range(img.shape[1]):\n",
    "                if num_distinct[i+1] == 0 or num_distinct_next[i+1] == 0:\n",
    "                    continue\n",
    "                start = num_distinct[i]\n",
    "                end = num_distinct_next[i+1] - 1\n",
    "                img[row[start]:row_next[end], i] = label\n",
    "\n",
    "\n",
    "#     fig, arr = plt.subplots(1,1,figsize=(14,10))\n",
    "#     arr.imshow(img)\n",
    "#     fig.show()\n",
    "    \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44adbf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_holes(img):\n",
    "    col, row = np.where(img.T == 0)\n",
    "    col = list(set(col))\n",
    "    if len(col) == 0:\n",
    "        return None, -1\n",
    "    return img[:, col], col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e89c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(img, num_line_fixes=2):\n",
    "    index_color = np.array(np.where(img.ravel() != 0)[0])\n",
    "    row = index_color // img.shape[1]\n",
    "    row_min = row[0]\n",
    "    row_max = row[-1]\n",
    "    \n",
    "    row_11, col_11, num_distinct_11 = get_index(img.T.ravel(), 11, img.shape)\n",
    "    img[row_11, col_11] = 10\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(num_line_fixes):\n",
    "        for row in range(row_min, row_max+1):\n",
    "            for col in range(1, img.shape[1] - 1):\n",
    "                if img[row, col-1] == img[row, col+1] and img[row, col] != img[row, col-1]:\n",
    "                    img[row, col] = img[row, col-1]\n",
    "\n",
    "                n = 2\n",
    "                if col > (n-1) and col < img.shape[1] - n and img[row, col-n] == img[row, col+n] and img[row, col] != img[row, col-n]:\n",
    "                    img[row, col] = img[row, col-n]\n",
    "\n",
    "\n",
    "                n = 4\n",
    "                if col > (n-1) and col < img.shape[1] - n and img[row, col-n] == img[row, col+n] and img[row, col] != img[row, col-n]:\n",
    "                    img[row, col] = img[row, col-n]\n",
    "    \n",
    "    unique_labels = np.sort(np.unique(img)[1:])\n",
    "    row_color, col_color, num_distinct_color = row_col_distinct_bool_array(img.T.ravel() != 0, img.shape)\n",
    "    \n",
    "    bg_top_label = 11\n",
    "    if unique_labels[0] != 1:\n",
    "        bg_top_label = unique_labels[0]\n",
    "    \n",
    "    bg_bot_label = 12 \n",
    "    if unique_labels[-1] != 10:\n",
    "        bg_bot_label = unique_labels[-1]\n",
    "        \n",
    "    for i in range(img.shape[1]):\n",
    "        img[:row_color[num_distinct_color[i]], i] = bg_top_label\n",
    "        img[row_color[num_distinct_color[i+1] - 1]+1:, i] = bg_bot_label\n",
    "            \n",
    "#     fig,arr = plt.subplots(1,1,figsize=(14,10))\n",
    "#     arr.imshow(img)\n",
    "#     fig.show()\n",
    "    \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8894d483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2160fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# './HeidelbergTraining/images_input_labeled/images_input_labeled0299.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efd74d9",
   "metadata": {},
   "source": [
    "# loop to create labeled data and corresponding gt label using earlier functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d002da21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {1920, 1175}\n",
    "# {1017, 986, 635}\n",
    "i = 0\n",
    "    \n",
    "count = 0\n",
    "file_count = 0\n",
    "full_path = \"/data/yue/heidelberg_segmentation\"\n",
    "# with open(os.path.join(total_path, \"HeidelbergTraining/original_image_paths.txt\"), \"r\") as img_txt_file:\n",
    "#     with open(os.path.join(total_path, \"HeidelbergTraining/original_mask_paths.txt\"), \"r\") as mask_txt_file:\n",
    "\n",
    "color_images = []\n",
    "gray_images = []\n",
    "actual_location = []\n",
    "\n",
    "total_imgs = 0\n",
    "\n",
    "\n",
    "for i, (img_path, mask_path) in enumerate(zip(image_path_list, mask_path_list)):\n",
    "    if \"NORMAL\" not in img_path:\n",
    "        continue\n",
    "    else:\n",
    "        count += 1\n",
    "    \n",
    "    \n",
    "#     if count < 7:\n",
    "#         continue\n",
    "    \n",
    "#     if count > 3:\n",
    "#         break\n",
    "        \n",
    "#     print(img_path[img_path.find(\"./\"):])\n",
    "#     print(mask_path[mask_path.find(\"./\"):])\n",
    "    img1, _, _ = get_black_white(np.array(Image.open(img_path[img_path.find(\"./\"):]).convert(\"L\")))\n",
    "    img2, crop_start, crop_end = get_black_white(np.array(Image.open(mask_path[mask_path.find(\"./\"):]).convert(\"L\")))\n",
    "\n",
    "    \n",
    "    \n",
    "    color_img2 = np.array(Image.open(mask_path[mask_path.find(\"./\"):]))[50:-100, crop_start:crop_end, :]\n",
    "\n",
    "#     print(color_img2.shape)\n",
    "#     print(img2.shape)\n",
    "\n",
    "    size1 = img1.shape\n",
    "    size2 = img2.shape\n",
    "\n",
    "    if size1[0] < 128 or size1[1] < 128:\n",
    "        continue\n",
    "\n",
    "    img2 = np.array(Image.fromarray(img2).resize((size1[1], size1[0])))\n",
    "    color_img2 = np.array(Image.fromarray(color_img2).resize((size1[1], size1[0])))\n",
    "\n",
    "    translation = match_to_img(img1, color_img2[:, :, 0])\n",
    "    color_img2 = np.concatenate((color_img2[translation:, :, :], color_img2[:translation, :, :]), axis=0)\n",
    "    num_image_crops = 0\n",
    "\n",
    "    cropped_img1, xstart, ystart = get_img_cropped(img1)\n",
    "    if cropped_img1 is not None:\n",
    "        total_imgs += 1\n",
    "        cropped_color_img2 = color_img2[ystart:ystart+cropped_img1.shape[0], xstart:xstart+cropped_img1.shape[1], :]\n",
    "        cropped_color_img2 = reshape_to_512(cropped_color_img2)\n",
    "        cropped_img1 = reshape_to_512(cropped_img1)\n",
    "        color_images.append(cropped_color_img2)\n",
    "        gray_images.append(cropped_img1)\n",
    "        actual_location.append((img_path, mask_path))\n",
    "#         fig,arr = plt.subplots(1, 2, figsize=(14,10))\n",
    "#         arr[0].imshow(cropped_img1)\n",
    "#         arr[1].imshow(cropped_color_img2)\n",
    "#         fig.show()\n",
    "        num_image_crops += 1\n",
    "\n",
    "        cropped_img1_half, x2, ystart = get_img_cropped(img1[:, :xstart + cropped_img1.shape[1] // 2])\n",
    "        if cropped_img1_half is not None:\n",
    "            cropped_color_img2 = color_img2[ystart:ystart+cropped_img1_half.shape[0], x2:x2+cropped_img1_half.shape[1], :]\n",
    "            cropped_color_img2 = reshape_to_512(cropped_color_img2)\n",
    "            cropped_img1_half = reshape_to_512(cropped_img1_half)\n",
    "            color_images.append(cropped_color_img2)\n",
    "            gray_images.append(cropped_img1_half)\n",
    "            actual_location.append((img_path, mask_path))\n",
    "#             fig,arr = plt.subplots(1, 2, figsize=(14,10))\n",
    "#             arr[0].imshow(cropped_img1_half)\n",
    "#             arr[1].imshow(cropped_color_img2)\n",
    "#             fig.show()\n",
    "            num_image_crops += 1\n",
    "        \n",
    "\n",
    "        cropped_img1_half, x2, ystart = get_img_cropped(img1[:, xstart+cropped_img1.shape[1] // 2:])\n",
    "        if cropped_img1_half is not None:\n",
    "            xindex = xstart + cropped_img1.shape[1] // 2 + x2\n",
    "            cropped_color_img2 = color_img2[ystart:ystart+cropped_img1_half.shape[0], xindex:xindex+cropped_img1_half.shape[1], :]\n",
    "            cropped_color_img2 = reshape_to_512(cropped_color_img2)\n",
    "            cropped_img1_half = reshape_to_512(cropped_img1_half)\n",
    "            color_images.append(cropped_color_img2)\n",
    "            gray_images.append(cropped_img1_half)\n",
    "            actual_location.append((img_path, mask_path))\n",
    "#             fig,arr = plt.subplots(1, 2, figsize=(14,10))\n",
    "#             arr[0].imshow(cropped_img1_half)\n",
    "#             arr[1].imshow(cropped_color_img2)\n",
    "#             fig.show()\n",
    "            num_image_crops += 1\n",
    "\n",
    "    print(\"%s, \"%num_image_crops, end=\"\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7e8fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f12e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(color_images))\n",
    "print(len(gray_images))\n",
    "print(len(actual_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05133d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_images_labeled = label_lines(color_images)\n",
    "print(len(color_images_labeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e363da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(color_images_labeled)): \n",
    "    print(\".\", end=\"\")\n",
    "    img = np.copy(color_images_labeled[i])\n",
    "    img = fill(img)\n",
    "    img = post_process(img)\n",
    "    \n",
    "    color_images_labeled[i] = img\n",
    "    \n",
    "    img_fp = actual_location[i][0]\n",
    "    mask_fp = actual_location[i][1]\n",
    "    \n",
    "    img_fp = img_fp[img_fp.find(\"./\"):]\n",
    "    mask_fp = mask_fp[mask_fp.find(\"./\"):]\n",
    "    \n",
    "    actual_location[i] = (img_fp, mask_fp)\n",
    "    \n",
    "#     fig,arr = plt.subplots(1,2,figsize=(14,10))\n",
    "#     arr[0].imshow(color_images_labeled[i])\n",
    "#     arr[1].imshow(img)\n",
    "#     fig.show()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743fcfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_img_save_path = \"./HeidelbergTraining/images_input_labeled\"\n",
    "labeled_mask_save_path = \"./HeidelbergTraining/images_masks\"\n",
    "\n",
    "print(\"%s\\n%s\"%(os.path.isdir(labeled_img_save_path), os.path.isdir(labeled_mask_save_path)))\n",
    "\n",
    "# num_diseased = 0\n",
    "num_diseased = 292\n",
    "\n",
    "with open(\"./HeidelbergTraining/images_input_labeled_paths.txt\", \"a\") as labeled_file:\n",
    "    with open(\"./HeidelbergTraining/images_masks_paths.txt\", \"a\") as mask_file:\n",
    "        \n",
    "        img_data = \"\"\n",
    "        mask_data = \"\"\n",
    "        \n",
    "        for i,(img, mask, location) in enumerate(zip(gray_images, color_images_labeled, actual_location)):\n",
    "\n",
    "            img = Image.fromarray(img.astype(\"uint8\"))\n",
    "            mask = Image.fromarray(mask.astype(\"uint8\"))\n",
    "            \n",
    "            img_name = \"images_input_labeled%04d\"%(i+num_diseased)\n",
    "            mask_name = \"images_masks%04d\"%(i+num_diseased)\n",
    "            \n",
    "            img.save(os.path.join(labeled_img_save_path, \"%s.png\"%img_name))\n",
    "            mask.save(os.path.join(labeled_mask_save_path, \"%s.png\"%mask_name))\n",
    "            \n",
    "            img_data += \"%s: %s\\n\"%(img_name, os.path.abspath(location[0]))\n",
    "            mask_data += \"%s: %s\\n\"%(mask_name, os.path.abspath(location[1]))\n",
    "            \n",
    "            print(\".\", end=\"\")\n",
    "        \n",
    "        labeled_file.write(img_data)\n",
    "        mask_file.write(mask_data)\n",
    "print()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65519424",
   "metadata": {},
   "source": [
    "# helper function to get valid mactel files from pre-created list of valid mactel files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77586370",
   "metadata": {},
   "source": [
    "# only diseased images with a mactel severity >= 4 are used as unlabeled data for semi-supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ce5ff3",
   "metadata": {},
   "source": [
    "## severities can be found here: /data/yue/mactel/representation/mactel_gradings_OPT_OCT_Volume IR_combined_closest_6m.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0960c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dir_list(path=\"\", lower_bound=0, upper_bound=10000, dot_num=10000):\n",
    "    if not os.path.isdir(path):\n",
    "        print(\"not a valid path\")\n",
    "        return []\n",
    "    \n",
    "    f = os.scandir(path)\n",
    "    \n",
    "    files = []\n",
    "    i = -1\n",
    "    for entry in f:\n",
    "        i += 1\n",
    "        if i < lower_bound:\n",
    "            continue\n",
    "            \n",
    "        elif i % dot_num == 0 and i > 0:\n",
    "            print(\".\", end=\" \")\n",
    "            \n",
    "        if i >= upper_bound:\n",
    "            break\n",
    "            \n",
    "        if entry.is_file():\n",
    "            files.append(entry.path)\n",
    "    \n",
    "    print(\".\" if upper_bound % dot_num > 0 else \"\")\n",
    "    print(\"files from [%s, %s)\"%(lower_bound, upper_bound))\n",
    "    print(\"each dot above represents ~%s files scanned (len(files)/%s + 1)\\nnum files in list: %s\"%(dot_num, dot_num, len(files)))\n",
    "    return files\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5025620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_mactel_file(mactel_gradings, full_name=\"\", verbose=False):\n",
    "    d_id = full_name[full_name.find(\"converted/\")+10:full_name.find(\".1_\")+2]\n",
    "    if verbose:\n",
    "        print(d_id)\n",
    "    row = mactel_gradings[mactel_gradings[\"dicomID\"] == d_id]\n",
    "\n",
    "    if len(row) > 0:\n",
    "        index = row.iloc[0].name\n",
    "        valid = int(mactel_gradings[index:index+1][\"stage\"])\n",
    "        if verbose:\n",
    "            print(\"matching dicom ID found!\\ndicom ID: %s\\nmactel severity: %s\"%(row[\"dicomID\"][index], valid))\n",
    "            if valid < 4:\n",
    "                print()\n",
    "        return valid\n",
    "\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"no matching dicom ID found in CSV\\n\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b89772",
   "metadata": {},
   "source": [
    "# loop to create unlabeled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7abe911",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../mactel/representation/mactel_gradings_OPT_OCT_Volume IR_combined_closest_6m.csv\"\n",
    "mactel_gradings = pd.read_csv(path, delimiter=\",\")\n",
    "# print(mactel_gradings[:1])\n",
    "\n",
    "numfiles = get_dir_list(path=\"../mactel/representation/dicom_converted\", lower_bound=0, upper_bound=100000)\n",
    "print(len(numfiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ed6e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1\n",
    "count = 0\n",
    "\n",
    "print(len(numfiles))\n",
    "\n",
    "severity5 = []\n",
    "severity4 = []\n",
    "\n",
    "for file in numfiles:\n",
    "    i += 1\n",
    "    \n",
    "    file_id = get_valid_mactel_file(mactel_gradings, full_name=file, verbose=False)\n",
    "    if (file_id > 3):\n",
    "#         print(\"hooray\\n\")\n",
    "        count += 1\n",
    "        if (file_id % 10 == 5):\n",
    "            severity5.append(file)\n",
    "        else:\n",
    "            severity4.append(file)\n",
    "\n",
    "\n",
    "print(\"num file w/ mactel severity >= 4: %s\\nnum files with 4: %s\\nnumfiles with 5: %s\"%(count, len(severity4), len(severity5)))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33702b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.path.isdir(\"./HeidelbergTraining/images_input_unlabeled\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c654c654",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_img_path_list = severity5\n",
    "\n",
    "count = 0\n",
    "unlabeled_img_save_path = \"./HeidelbergTraining/images_input_unlabeled\"\n",
    "\n",
    "\n",
    "def crop_and_save_unlabeled_images(unlabeled_img_path_list, unlabeled_img_save_path, count):\n",
    "    for i, unlabeled_img_path in enumerate(sorted(unlabeled_img_path_list)):\n",
    "        if i % 50 == 0:\n",
    "            print(\".\", end=\"\")\n",
    "\n",
    "        unlabeled_img = np.array(Image.open(unlabeled_img_path))\n",
    "        with open(\"./HeidelbergTraining/images_input_unlabeled_paths.txt\", \"a\") as unlabeled_save_file:\n",
    "            cropped_img1, xstart, ystart = get_img_cropped(unlabeled_img)\n",
    "            if cropped_img1 is not None:\n",
    "                save_img = Image.fromarray(reshape_to_512(cropped_img1).astype(\"uint8\"))\n",
    "                name = \"images_input_unlabeled%04d.png\"%count\n",
    "                save_img.save(os.path.join(unlabeled_img_save_path, name))\n",
    "                unlabeled_save_file.write(\"%s: %s\\n\"%(name, os.path.abspath(unlabeled_img_path)))\n",
    "                count += 1\n",
    "\n",
    "#                 plt.imshow(save_img)\n",
    "#                 plt.show()\n",
    "\n",
    "                cropped_img1_half, x2, ystart = get_img_cropped(unlabeled_img[:, :xstart + cropped_img1.shape[1] // 2])\n",
    "                if cropped_img1_half is not None:\n",
    "                    save_img = Image.fromarray(reshape_to_512(cropped_img1_half).astype(\"uint8\"))\n",
    "                    name = \"images_input_unlabeled%04d.png\"%count\n",
    "                    save_img.save(os.path.join(unlabeled_img_save_path, name))\n",
    "                    unlabeled_save_file.write(\"%s: %s\\n\"%(name, os.path.abspath(unlabeled_img_path)))\n",
    "                    count += 1\n",
    "\n",
    "#                     plt.imshow(save_img)\n",
    "#                     plt.show()\n",
    "\n",
    "                cropped_img1_half, x2, ystart = get_img_cropped(unlabeled_img[:, xstart+cropped_img1.shape[1] // 2:])\n",
    "                if cropped_img1_half is not None:\n",
    "                    save_img = Image.fromarray(reshape_to_512(cropped_img1_half).astype(\"uint8\"))\n",
    "                    name = \"images_input_unlabeled%04d.png\"%count\n",
    "                    save_img.save(os.path.join(unlabeled_img_save_path, name))\n",
    "                    unlabeled_save_file.write(\"%s: %s\\n\"%(name, os.path.abspath(unlabeled_img_path)))\n",
    "                    count += 1\n",
    "\n",
    "#                     plt.imshow(save_img)\n",
    "#                     plt.show()\n",
    "    print()\n",
    "    return count \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227d5c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./HeidelbergTraining/images_input_unlabeled_paths.txt\", \"w\") as file:\n",
    "        print(\"cleared previous data in images_input_unlabeled_paths.txt\")\n",
    "num_files = crop_and_save_unlabeled_images(severity5, \"./HeidelbergTraining/images_input_unlabeled\", 0)\n",
    "num_files = crop_and_save_unlabeled_images(severity4, \"./HeidelbergTraining/images_input_unlabeled\", num_files)\n",
    "print(num_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf230542",
   "metadata": {},
   "source": [
    "# loop to create baseline dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2154e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_p = \"./data/Segmentations diseased eyes - MacTel/MacTel eyes with segmentations\"\n",
    "labeled_paths = []\n",
    "baseline_paths = []\n",
    "num_diseased = 292\n",
    "diseased_train_cutoff = 230\n",
    "diseased_valid_cutoff = 262\n",
    "\n",
    "actual_locations = []\n",
    "\n",
    "with open(\"./HeidelbergTraining/images_input_labeled_paths.txt\", \"r\") as labeled_file:\n",
    "    \n",
    "    labeled_paths = sorted(labeled_file.readlines())[diseased_valid_cutoff:num_diseased]\n",
    "    actual_locations = [\"images_masks%s\"%elem[elem.find(\":\") - 4:elem.find(\":\")].strip() for elem in labeled_paths]\n",
    "    labeled_paths = [elem[elem.find(\":\")+2:].strip() for elem in labeled_paths]\n",
    "    \n",
    "    baseline_paths = [elem[elem.find(\"NHOR\"):elem.find(\"..png\")] for elem in labeled_paths]\n",
    "    baseline_paths = [os.path.join(baseline_p, \"%s.png\"%elem) for elem in baseline_paths]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44c1a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(actual_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5a835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_paths = []\n",
    "m_path = \"./HeidelbergTraining/images_masks\"\n",
    "for dir_name, dirs, files in os.walk(m_path):\n",
    "    mask_paths = sorted([os.path.join(m_path, f) for f in files if f.endswith(\".png\")])\n",
    "\n",
    "mask_paths = mask_paths[diseased_valid_cutoff:num_diseased]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba75deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_paths = sorted(list(set(labeled_paths)))\n",
    "baseline_paths = sorted(list(set(baseline_paths)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6d365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corresponding_paths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c8b669",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "baseline_image_list = []\n",
    "\n",
    "for i in range(len(baseline_paths)):\n",
    "    baseline_p = baseline_paths[i]\n",
    "    labeled_p = labeled_paths[i]\n",
    "    \n",
    "    img_labeled, crop_start, crop_end = get_black_white(np.array(Image.open(labeled_p).convert(\"L\")))\n",
    "    img_baseline, _, _ = get_black_white(np.array(Image.open(baseline_p).convert(\"L\")))\n",
    "    \n",
    "    baseline_img_color = np.array(Image.open(baseline_p))[50:-100, crop_start:crop_end]\n",
    "    baseline_img_color = np.array(Image.fromarray(baseline_img_color.astype(\"uint8\")).resize((img_labeled.shape[1], img_labeled.shape[0])))\n",
    "    \n",
    "    translation = match_to_img(img_labeled, baseline_img_color[:, :, 0])\n",
    "    baseline_img_color = np.concatenate((baseline_img_color[translation:, :, :], baseline_img_color[:translation, :, :]), axis=0)\n",
    "    \n",
    "    cropped_img1, xstart, ystart = get_img_cropped(img_labeled)\n",
    "    if cropped_img1 is not None:\n",
    "        cropped_color_img2 = baseline_img_color[ystart:ystart+cropped_img1.shape[0], xstart:xstart+cropped_img1.shape[1], :]\n",
    "        cropped_color_img2 = reshape_to_512(cropped_color_img2)\n",
    "        cropped_img1 = reshape_to_512(cropped_img1)\n",
    "#         fig,arr = plt.subplots(1, 3, figsize=(14,10))\n",
    "#         arr[0].imshow(cropped_img1)\n",
    "#         arr[2].imshow(np.array(Image.open(mask_paths[count]).convert(\"L\")))\n",
    "#         arr[1].imshow(cropped_color_img2)\n",
    "#         fig.show()\n",
    "#         plt.show()\n",
    "    \n",
    "        baseline_image_list.append(cropped_color_img2)\n",
    "        count += 1\n",
    "\n",
    "        \n",
    "        \n",
    "        cropped_img1_half, x2, ystart = get_img_cropped(img_labeled[:, :xstart + cropped_img1.shape[1] // 2])\n",
    "        if cropped_img1_half is not None:\n",
    "            cropped_color_img2 = baseline_img_color[ystart:ystart+cropped_img1_half.shape[0], x2:x2+cropped_img1_half.shape[1], :]\n",
    "            cropped_color_img2 = reshape_to_512(cropped_color_img2)\n",
    "            cropped_img1_half = reshape_to_512(cropped_img1_half)\n",
    "#             fig,arr = plt.subplots(1, 3, figsize=(14,10))\n",
    "#             arr[0].imshow(cropped_img1_half)\n",
    "#             arr[2].imshow(np.array(Image.open(mask_paths[count]).convert(\"L\")))\n",
    "#             arr[1].imshow(cropped_color_img2)\n",
    "#             fig.show()\n",
    "#             plt.show()\n",
    "            \n",
    "            baseline_image_list.append(cropped_color_img2)\n",
    "            count += 1\n",
    "        \n",
    "\n",
    "        cropped_img1_half, x2, ystart = get_img_cropped(img_labeled[:, xstart+cropped_img1.shape[1] // 2:])\n",
    "        if cropped_img1_half is not None:\n",
    "            xindex = xstart + cropped_img1.shape[1] // 2 + x2\n",
    "            cropped_color_img2 = baseline_img_color[ystart:ystart+cropped_img1_half.shape[0], xindex:xindex+cropped_img1_half.shape[1], :]\n",
    "            cropped_color_img2 = reshape_to_512(cropped_color_img2)\n",
    "            cropped_img1_half = reshape_to_512(cropped_img1_half)\n",
    "#             fig,arr = plt.subplots(1, 3, figsize=(14,10))\n",
    "#             arr[0].imshow(cropped_img1_half)\n",
    "#             arr[2].imshow(np.array(Image.open(mask_paths[count]).convert(\"L\")))\n",
    "#             arr[1].imshow(cropped_color_img2)\n",
    "#             fig.show()\n",
    "#             plt.show()\n",
    "            \n",
    "            baseline_image_list.append(cropped_color_img2)\n",
    "            count += 1\n",
    "    \n",
    "    print(baseline_img_color.shape)\n",
    "    print(img_labeled.shape)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0c6610",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_image_list_labeled = label_lines(baseline_image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4854c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(baseline_image_list_labeled))\n",
    "print(len(actual_locations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b7d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=23\n",
    "\n",
    "fig,arr = plt.subplots(1,2,figsize=(14,10))\n",
    "arr[0].imshow(baseline_image_list_labeled[N])\n",
    "arr[1].imshow(np.array(Image.open(\"./HeidelbergTraining/images_masks/%s.png\"%actual_locations[N]).convert(\"L\")))\n",
    "fig.show()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6519b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "corresponding_locations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cbd680",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_image_save_path = \"./HeidelbergTraining/images_baseline/baseline_full_image\"\n",
    "print(os.path.isdir(full_image_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9b57f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"./HeidelbergTraining/images_baseline_paths.txt\", \"w\") as baseline_save_file:\n",
    "    print(\"cleared\")\n",
    "\n",
    "mask_save_path = \"./HeidelbergTraining/images_baseline/baseline_masks\"\n",
    "image_save_path = \"./HeidelbergTraining/images_baseline/baseline_images\"\n",
    "full_image_save_path = \"./HeidelbergTraining/images_baseline/baseline_full_image\"\n",
    "\n",
    "count = 0\n",
    "    \n",
    "for i in range(len(baseline_image_list_labeled)):\n",
    "#     if i > 3:\n",
    "#         break\n",
    "#     print(\".\", end=\"\")\n",
    "    print(i)\n",
    "    img = np.copy(baseline_image_list_labeled[i])\n",
    "    img = fill(img, baseline=True)\n",
    "    img = post_process(img)\n",
    "    mask = np.array(Image.open(mask_paths[i]).convert(\"L\"))\n",
    "    \n",
    "    mask, col = only_holes(mask)\n",
    "    if mask is not None:\n",
    "        full_img = Image.fromarray(img.astype(\"uint8\"))\n",
    "        full_img.save(os.path.join(full_image_save_path, \"baseline_full_image%04d.png\"%i))\n",
    "        \n",
    "        img = img[:, col]\n",
    "#         print(mask.shape)\n",
    "#         fig,arr = plt.subplots(1,2,figsize=(14,10))\n",
    "#         arr[0].imshow(img)\n",
    "#         arr[1].imshow(mask)\n",
    "#         fig.show()\n",
    "#         plt.show()\n",
    "\n",
    "        img = Image.fromarray(img.astype(\"uint8\"))\n",
    "        mask = Image.fromarray(mask.astype(\"uint8\"))\n",
    "        \n",
    "        with open(\"./HeidelbergTraining/images_baseline_paths.txt\", \"a\") as baseline_save_file:\n",
    "            img_name = \"baseline_images%04d\"%i\n",
    "            mask_name = \"baseline_masks%04d\"%i\n",
    "            \n",
    "            img.save(os.path.join(image_save_path, \"%s.png\"%img_name))\n",
    "            mask.save(os.path.join(mask_save_path, \"%s.png\"%mask_name))\n",
    "            \n",
    "            baseline_save_file.write(\"%s, %s: %s\\n\"%(img_name,mask_name,\"./HeidelbergTraining/images_masks/%s.png\"%actual_locations[count]))\n",
    "            \n",
    "    count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6dc338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
