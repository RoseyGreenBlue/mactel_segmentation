{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7376c17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('./TorchSemiSeg/exp.voc/voc8.res50v3+.CPS+CutMix/')\n",
    "from network import Network\n",
    "import dataloader\n",
    "from config import config\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from engine.engine import Engine\n",
    "from custom_collate import SegCollate\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62704260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch                     1.0.0                    pypi_0    pypi\n",
    "# torchsummary              1.5.1                    pypi_0    pypi\n",
    "# torchvision               0.2.2.post3              pypi_0    pypi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8daf97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER_NAMES_14 = [\n",
    "    \"ILM\", \n",
    "    \"RNFL\",\n",
    "    \"GCL\", \n",
    "    \"IPL\", \n",
    "    \"INL\", \n",
    "    \"OPL\", \n",
    "    \"ELM\", \n",
    "    \"PR1\", \n",
    "    \"PR2\", \n",
    "    \"RPE\", \n",
    "    \"Collapsed Layers\",\n",
    "    \"Cycsts\",\n",
    "    \"Vitreous\", \n",
    "    \"Choroid/Sclera\"\n",
    "]\n",
    "total_path = \"./\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fad7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_list(path):\n",
    "    ret = []\n",
    "    for root,dirs,files in os.walk(path):\n",
    "        ret = sorted([path + \"/\" + f for f in files if f[-4:] == \".png\"])\n",
    "        if len(ret) > 0:\n",
    "            break\n",
    "    return ret\n",
    "\n",
    "image_input_labeled_path = os.path.join(total_path, \"HeidelbergTraining/images_input_labeled\")\n",
    "image_mask_path = os.path.join(total_path, \"HeidelbergTraining/images_masks\")\n",
    "baseline_img_path = os.path.join(total_path, \"HeidelbergTraining/images_baseline/baseline_images\")\n",
    "baseline_mask_path = os.path.join(total_path, \"HeidelbergTraining/images_baseline/baseline_masks\")\n",
    "baseline_full_img_path = os.path.join(total_path, \"HeidelbergTraining/images_baseline/baseline_full_image\")\n",
    "\n",
    "\n",
    "# go to images_input_labeled_paths.txt, images_masks_paths.txt for more info on these numbers\n",
    "# 80:10:10 split at patient level\n",
    "num_diseased = 292\n",
    "diseased_train_cutoff = 230\n",
    "normal_train_cutoff = 1381\n",
    "diseased_valid_cutoff = 262\n",
    "normal_valid_cutoff = 1521\n",
    "\n",
    "images_all_labeled = make_list(image_input_labeled_path)\n",
    "masks_all = make_list(image_mask_path)\n",
    "\n",
    "image_list_train = images_all_labeled[num_diseased:normal_train_cutoff]\n",
    "mask_list_train_13 = masks_all[num_diseased:normal_train_cutoff]\n",
    "\n",
    "dimgs = images_all_labeled[:diseased_train_cutoff]\n",
    "dmasks = masks_all[:diseased_train_cutoff]\n",
    "\n",
    "while len(image_list_train) < (2 * (normal_train_cutoff - num_diseased)):\n",
    "    image_list_train.extend(dimgs)\n",
    "    mask_list_train_13.extend(dmasks)\n",
    "\n",
    "del dimgs\n",
    "del dmasks\n",
    "\n",
    "d_image_list_cv = images_all_labeled[diseased_train_cutoff:diseased_valid_cutoff]\n",
    "d_mask_list_cv_13 = masks_all[diseased_train_cutoff:diseased_valid_cutoff]\n",
    "\n",
    "d_image_list_test = []\n",
    "d_mask_list_test_13 = []\n",
    "\n",
    "with open(\"./HeidelbergTraining/images_baseline_paths.txt\", \"r\") as baseline_info:\n",
    "    data = baseline_info.readlines()\n",
    "    d_mask_list_test_13 = [elem[elem.find(\":\")+2:].strip() for elem in data]\n",
    "    d_image_list_test = [\"./HeidelbergTraining/images_input_labeled/images_input_labeled%s.png\"%elem[elem.find(\".png\")-4:elem.find(\".png\")] for elem in d_mask_list_test_13]\n",
    "\n",
    "image_list_train = sorted(image_list_train)\n",
    "mask_list_train_13 = sorted(mask_list_train_13)\n",
    "\n",
    "d_image_list_cv = sorted(d_image_list_cv)\n",
    "d_mask_list_cv_13 = sorted(d_mask_list_cv_13)\n",
    "\n",
    "d_image_list_test = sorted(d_image_list_test)\n",
    "d_mask_list_test_13 = sorted(d_mask_list_test_13)\n",
    "\n",
    "baseline_images = make_list(baseline_img_path)\n",
    "baseline_masks = make_list(baseline_mask_path)\n",
    "baseline_full_images = make_list(baseline_full_img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96bf2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d_image_list_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf2a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./TorchSemiSeg/DATA/pascal_voc/subset_train_aug2/train_aug_labeled_1-8.txt\"\n",
    "with open(save_path, \"r\") as labeled_file:\n",
    "    data = labeled_file.readlines()\n",
    "    data = [elem.strip() for elem in data]\n",
    "    \n",
    "    test_imgs = [\"%04d.png\"%i for i in range(diseased_valid_cutoff, num_diseased)]\n",
    "    for img in test_imgs:\n",
    "        if img in data:\n",
    "            print(\"NONONONONONO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab592c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cps_save_path = \"./TorchSemiSeg/snapshot/snapshot/epoch-last.pth\"\n",
    "pretrained_model_path = \"./TorchSemiSeg/DATA/pytorch-weight/resnet50_v1c.pth\"\n",
    "\n",
    "print(os.path.isfile(cps_save_path))\n",
    "print(os.path.isfile(pretrained_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fd287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_rearrange(image):\n",
    "    image = np.concatenate((image[:, :, 0][np.newaxis, :, :], image[:, :, 1][np.newaxis, :, :], image[:, :, 2][np.newaxis, :, :]), axis=0)\n",
    "    return image\n",
    "\n",
    "def get_test_image_mask(N):\n",
    "    img = np_rearrange(dataloader.normalize(cv2.imread(d_image_list_test[N]), 0, 1))\n",
    "    mask = cv2.imread(d_mask_list_test_13[N], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    img = torch.from_numpy(np.ascontiguousarray(img))[None, :, :, :].float().to(device)\n",
    "    mask = torch.from_numpy(np.ascontiguousarray(mask))[None, :, :].long().to(device)\n",
    "\n",
    "    return (img, mask)\n",
    "\n",
    "def output_rearrange(output, num_classes):\n",
    "    argmax_output = output[0][0].detach()[:, :, None]\n",
    "    for i in range(1, num_classes):\n",
    "        argmax_output = torch.cat((argmax_output, output[0][i].detach()[:, :, None]), dim=2)\n",
    "    \n",
    "    return torch.argmax(argmax_output, dim=-1).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dcc81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction='mean', ignore_index=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144001fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network(\n",
    "    config.num_classes, \n",
    "    criterion=criterion, \n",
    "    pretrained_model=config.pretrained_model,\n",
    "    norm_layer=torch.nn.BatchNorm2d\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4df499",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(cps_save_path)\n",
    "model.load_state_dict(state_dict[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414d4d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_iou(image, mask, n_class=0):\n",
    "    actual_positives = mask == n_class\n",
    "    predicted_positives = image == n_class\n",
    "    \n",
    "    intersection = np.sum(np.logical_and(actual_positives, predicted_positives))\n",
    "    union = np.sum(np.logical_or(actual_positives, predicted_positives))\n",
    "    \n",
    "    if union == 0 and intersection == 0:\n",
    "        return 1\n",
    "\n",
    "    iou = intersection/union\n",
    "    return iou\n",
    "\n",
    "def get_iou(output, mask, n_classes=list(range(14))):\n",
    "    ious = []\n",
    "    for i in n_classes:\n",
    "        if i < 10:\n",
    "            ious.append(calc_iou(output, mask, i+1))\n",
    "        elif i == 10:\n",
    "            ious.append(calc_iou(output, mask, 0))\n",
    "        elif i == 11 and len(n_classes) == 14:\n",
    "            ious.append(calc_iou(output, mask, 13))\n",
    "        elif len(n_classes) == 14:\n",
    "            ious.append(calc_iou(output, mask, i-1))\n",
    "        else:\n",
    "            ious.append(calc_iou(output, mask, i))\n",
    "        \n",
    "    mean_iou = sum(ious) / len(n_classes)\n",
    "    \n",
    "    return ious, mean_iou\n",
    "\n",
    "def add_13_label(output, image, mask):\n",
    "    avg_pooler = nn.AvgPool2d(4, stride=2).to(device)\n",
    "    reduced_mask = (avg_pooler(mask[None, :, :, :].float()))[0][0].detach().cpu().numpy()\n",
    "    reduced_output = (avg_pooler(output[None, None, :, :].float()))[0][0].detach().cpu().numpy()\n",
    "    reduced_image = (avg_pooler(image[:,0:1,:,:]))[0][0].detach().cpu().numpy()\n",
    "    \n",
    "    threshold = np.percentile(reduced_image, 25)\n",
    "\n",
    "    a = [reduced_image < threshold][0].astype(np.int8)\n",
    "    b = [reduced_output == 0][0].astype(np.int8)\n",
    "    b = ((a + b) // 2).astype(bool)\n",
    "\n",
    "    a = [reduced_image < threshold][0].astype(np.int8)\n",
    "    c = [reduced_mask == 0][0].astype(np.int8)\n",
    "    c = ((a + c) // 2).astype(bool)\n",
    "\n",
    "    yvals, xvals = np.where(c)\n",
    "    for (x,y) in zip(xvals, yvals):\n",
    "        mask[0, y*2:y*2+5, x*2:x*2+5] = 13\n",
    "\n",
    "    yvals, xvals = np.where(b)\n",
    "    for (x,y) in zip(xvals, yvals):\n",
    "        output[y*2:y*2+5,x*2:x*2+5] = 13\n",
    "    \n",
    "    return output, mask\n",
    "\n",
    "def evaluate_CPS_model(num_images, eval_model, show=False, name=\"DL_pytorch\", ignore_0=False, n_classes=list(range(14))):\n",
    "#     eval_model.train(False)\n",
    "    ious = [[] for i in range(len(n_classes))]\n",
    "    means = []\n",
    "    \n",
    "    eval_model.eval()\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        image,mask = get_test_image_mask(i)\n",
    "\n",
    "        output = eval_model.forward(image)\n",
    "        output = torch.from_numpy(output_rearrange(output, 13))\n",
    "        \n",
    "        avg_pooler = nn.AvgPool2d(4, stride=2).to(device)\n",
    "        reduced_mask = (avg_pooler(mask[None, :, :, :].float()))[0][0].detach().cpu().numpy()\n",
    "        reduced_output = (avg_pooler(output[None, None, :, :].float()))[0][0].detach().cpu().numpy()\n",
    "        reduced_image = (avg_pooler(image[:,0:1,:,:]))[0][0].detach().cpu().numpy()\n",
    "        \n",
    "        \n",
    "        output = output.numpy()\n",
    "        image = image[0][0].cpu().numpy()\n",
    "        mask = mask[0].cpu().numpy()\n",
    "\n",
    "        threshold = np.percentile(reduced_image, 25)\n",
    "\n",
    "        a = [reduced_image < threshold][0].astype(np.int8)\n",
    "        b = [reduced_output == 0][0].astype(np.int8)\n",
    "        b = ((a + b) // 2).astype(bool)\n",
    "\n",
    "        a = [reduced_image < threshold][0].astype(np.int8)\n",
    "        c = [reduced_mask == 0][0].astype(np.int8)\n",
    "        c = ((a + c) // 2).astype(bool)\n",
    "        \n",
    "        yvals, xvals = np.where(c)\n",
    "        for (x,y) in zip(xvals, yvals):\n",
    "            mask[y*2:y*2+5,x*2:x*2+5] = 13\n",
    "\n",
    "        yvals, xvals = np.where(b)\n",
    "        for (x,y) in zip(xvals, yvals):\n",
    "            output[y*2:y*2+5,x*2:x*2+5] = 13\n",
    "        \n",
    "        if show:\n",
    "            fig, arr = plt.subplots(1, 3, figsize=(14,10))\n",
    "            arr[0].imshow(mask)\n",
    "            arr[0].set_title(\"gt %s\"%i)\n",
    "            arr[1].imshow(output)\n",
    "            arr[1].set_title(\"prediction %s\"%i)\n",
    "            arr[2].imshow(image)\n",
    "            arr[2].set_title(\"input %s\"%i)\n",
    "            fig.show()\n",
    "            plt.show()\n",
    "        \n",
    "        iou_c, mean_c = get_iou(mask, output, n_classes=range(14))\n",
    "        \n",
    "        means.append(mean_c)\n",
    "        for j in range(len(ious)):\n",
    "            if j >= len(iou_c):\n",
    "                ious[j].append(0)\n",
    "            else:\n",
    "                ious[j].append(iou_c[j])\n",
    "                \n",
    "    means = sum(means)/len(means)\n",
    "    iou_data = []\n",
    "    for layer_name,layer in enumerate(ious):\n",
    "        iou_data.extend([(name, layer_name, layer_i) for layer_i in layer])\n",
    "        \n",
    "    iou_data = pd.DataFrame(iou_data, columns=[\"Class\", \"layer\", \"IOU\"])\n",
    "    \n",
    "    return iou_data,means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da776f0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iou_cps, mean_cps = evaluate_CPS_model(len(d_image_list_test), model, name=\"SSL\", n_classes=list(range(14)), show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718afa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dict(iou):\n",
    "    fig = px.box(iou, x=\"layer\", y=\"IOU\", color=\"Class\")\n",
    "    fig.update_layout(\n",
    "        xaxis = dict(\n",
    "            tickmode = 'array',\n",
    "            tickvals = list(range(14)),\n",
    "            ticktext = LAYER_NAMES_14\n",
    "        ),\n",
    "        boxgap=.7,\n",
    "    #         title=\"IOUs of different model architectures on the diseased test set by layer\",\n",
    "        title=\"IOU comparison of different models on the diseased test set\",\n",
    "        legend=dict(\n",
    "            y=-0.35,\n",
    "            x=0.01\n",
    "        ),\n",
    "        height=650\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "plot_dict(iou_cps)\n",
    "print(mean_cps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266e9d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_cps.to_csv(\"./HeidelbergTraining/CPS_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6983d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for i, (N, baseline_img_path) in enumerate(zip(range(len(d_image_list_test)), baseline_full_images)):\n",
    "    image,mask = get_test_image_mask(N)\n",
    "    baseline_full_image = np.array(Image.open(baseline_img_path).convert(\"L\"))\n",
    "    output = model.forward(image)\n",
    "    output = torch.from_numpy(output_rearrange(output, 13))\n",
    "    \n",
    "    output, mask = add_13_label(output, image, mask)\n",
    "    output = output.numpy().astype(\"uint8\")\n",
    "    \n",
    "    image_copy = Image.open(d_image_list_test[N]).convert(\"L\")\n",
    "    img_blended = Image.blend(Image.fromarray(output * 19), image_copy, 0.4)\n",
    "    \n",
    "    \n",
    "    fig,arr = plt.subplots(1,4,figsize=(14,10))\n",
    "    for a in arr:\n",
    "        a.axes.get_xaxis().set_visible(False)\n",
    "        a.axes.get_yaxis().set_visible(False)\n",
    "    \n",
    "    arr[0].imshow(image[0][0].cpu().numpy())\n",
    "    arr[1].imshow(output)\n",
    "    arr[2].imshow(np.array(img_blended))\n",
    "    arr[3].imshow(baseline_full_image)\n",
    "    fig.show()\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e47bf17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
